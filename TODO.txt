Make it work:
	- Implement schema access @done
	The bit that actually talks to Cassandra.
	- Implement activity feed protocol @done
	Exposes subscribe/unsubscribe, publish/unpublish, activity, object verbs.
	- Build HTTP service on protocol @done
	- Build client API for service	 @done
	- Build AR sugar on top of client API
Make it right:
	- Set up Cassandra staging cluster
	2-4 node cluster, smaller instances. Used for testing load, adding/removing nodes, etc.
	- Import checkin/activity data
	Write some script to convert data from PG to Chronologic.
	- Compare Chronologic feeds and gowalla-rails feeds
	Make sure it all matches up, fix where it doesn't.
Make it production:
	- Add logging, set up centralized collection/searching of logs
	Look into rsyslog or scribe for aggregating logs.
	- Add instrumentation, connect to Ganglia
	Track update, read times, transaction volume. Would be nice to track HTTP caching as well.
	- Set up health/capacity monitoring
	- Set up a client test cluster, run load tests
	1-2 nodes to see how many checkins/sec and feeds/sec we can handle
Make it whole:
	- Refactor activity feeds to use Chronologic
	- Refactor privacy controls to sit on top of data returned by Chronologic
	Move privacy checks out of views and controllers and into Chronologic client library
	- Refactor pagination to work with Chronologic
	Can will_paginate work smoothly with this, or will we need something duck-type compatible?
	- Add feature flipper for Chronologic feeds and publishing to Chronologic
	- Test/debug in staging and production
Make it the thing:
	- Remove feature flipper
	- Remove old activity code
	- Fill out documentation for writing to activity feeds and creating different timelines
	- Celebrate
